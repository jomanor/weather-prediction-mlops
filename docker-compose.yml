services:
  
  # MongoDB
  mongodb:
    image: mongo:6.0
    container_name: weather-mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE}
    volumes:
      - mongo-data:/data/db
    networks:
      - weather-network

  # Kafka
  kafka:
    image: apache/kafka:4.1.0
    container_name: weather-kafka
    ports:
      - "29092:29092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://localhost:9093,EXTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-broker-api-versions.sh", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - weather-network

  # Kafka Producer
  weather-producer:
    build: ./kafka-producer
    container_name: weather-producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BROKER: kafka:9092
      WEATHER_API_KEY: ${WEATHER_API_KEY}
    restart: unless-stopped
    networks:
      - weather-network

  # Kafka Consumer
  weather-consumer:
    build: ./kafka-consumer
    container_name: weather-consumer
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_started
    environment:
      KAFKA_BROKER: kafka:9092
      MONGO_URL: mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongodb:27017/weather_db?authSource=admin
    restart: unless-stopped
    networks:
      - weather-network

  # Fastapi API
  weather-api:
    build: ./api
    container_name: weather-api
    ports:
      - 8000:8000
    environment:
      MONGO_URL: mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongodb:27017/weather_db?authSource=admin
    depends_on:
      - mongodb
    restart: unless-stopped
    networks:
      - weather-network

  # Spark Master
  spark-master:
    image: apache/spark:3.5.5-python3
    container_name: spark-master
    command: >
      bash -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_MASTER_OPTS=-Dspark.rpc.message.maxSize=256
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - spark-logs:/opt/spark/spark-events
    networks:
      - weather-network
  
  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.5-python3
    container_name: spark-worker
    command: >
      bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    environment:
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_OPTS=-Dspark.rpc.message.maxSize=256
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - spark-logs:/opt/spark/spark-events
      - spark-tmp:/opt/spark-tmp
    networks:
      - weather-network

  # Spark History
  spark-history:
    image: apache/spark:3.5.5-python3
    container_name: spark-history
    command: >
      bash -c "/opt/spark/sbin/start-history-server.sh && tail -f /dev/null"
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events
      - SPARK_NO_DAEMONIZE=true
    ports:
      - "18080:18080"
    volumes:
      - spark-logs:/opt/spark/spark-events
    networks:
      - weather-network

  # Spark Scheduler
  spark-scheduler:
    build: ./spark-scheduler
    container_name: spark-scheduler
    environment:
      MONGO_URL: mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongodb:27017/weather_db?authSource=admin
    depends_on:
      - spark-master
      - spark-worker
      - mongodb
    volumes:
      - ./spark-jobs:/opt/spark-jobs
      - spark-tmp:/opt/spark-tmp
    networks:
      - weather-network
    restart: unless-stopped

volumes:
  mongo-data:
  kafka-data:
  spark-logs:
  spark-tmp:
networks:
  weather-network:
    driver: bridge